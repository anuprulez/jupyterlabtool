{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e862af-95ec-4fc8-86f3-bb8d00dab261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample_tf_code.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample_tf_code.py\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def train_step(images, labels, mnist_model, optimizer, loss_object):\n",
    "    loss_history = []\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = mnist_model(images, training=True)\n",
    "        tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "        loss_value = loss_object(labels, logits)\n",
    "    loss_history.append(loss_value.numpy().mean())\n",
    "    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))\n",
    "    return np.mean(loss_history), mnist_model\n",
    "\n",
    "\n",
    "def train(epochs, dataset, train_step):\n",
    "    tot_loss = []\n",
    "    weights = None\n",
    "\n",
    "    mnist_model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "        tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for (batch, (images, labels)) in enumerate(dataset):\n",
    "            b_loss, mnist_model = train_step(images, labels, mnist_model, optimizer, loss_object)\n",
    "            tot_loss.append(b_loss)\n",
    "    return mnist_model\n",
    "\n",
    "\n",
    "def rev_value():\n",
    "    (mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32), tf.cast(mnist_labels,tf.int64)))\n",
    "    dataset = dataset.shuffle(1000).batch(32)\n",
    "    return train(1, dataset, train_step)\n",
    "\n",
    "\n",
    "model = rev_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c43876f3-9e91-41b1-9377-6652038eecd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import tensorflow as tf\n",
      "\n",
      "\n",
      "def train_step(images, labels, mnist_model, optimizer, loss_object):\n",
      "    loss_history = []\n",
      "    with tf.GradientTape() as tape:\n",
      "        logits = mnist_model(images, training=True)\n",
      "        tf.debugging.assert_equal(logits.shape, (32, 10))\n",
      "        loss_value = loss_object(labels, logits)\n",
      "    loss_history.append(loss_value.numpy().mean())\n",
      "    grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
      "    optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))\n",
      "    return np.mean(loss_history), mnist_model\n",
      "\n",
      "\n",
      "def train(epochs, dataset, train_step):\n",
      "    tot_loss = []\n",
      "    weights = None\n",
      "\n",
      "    mnist_model = tf.keras.Sequential([\n",
      "        tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
      "                         input_shape=(None, None, 1)),\n",
      "        tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
      "        tf.keras.layers.GlobalAveragePooling2D(),\n",
      "        tf.keras.layers.Dense(10)\n",
      "    ])\n",
      "\n",
      "    optimizer = tf.keras.optimizers.Adam()\n",
      "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
      "\n",
      "    for epoch in range(epochs):\n",
      "        for (batch, (images, labels)) in enumerate(dataset):\n",
      "            b_loss, mnist_model = train_step(images, labels, mnist_model, optimizer, loss_object)\n",
      "            tot_loss.append(b_loss)\n",
      "    return mnist_model\n",
      "\n",
      "\n",
      "def rev_value():\n",
      "    (mnist_images, mnist_labels), _ = tf.keras.datasets.mnist.load_data()\n",
      "    dataset = tf.data.Dataset.from_tensor_slices((tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32), tf.cast(mnist_labels,tf.int64)))\n",
      "    dataset = dataset.shuffle(1000).batch(32)\n",
      "    return train(1, dataset, train_step)\n",
      "\n",
      "\n",
      "model = rev_value()def get_script_code(ipy_file_path, target_file_name=\"target-file.py\"):\n",
      "    from nbformat import read, NO_CONVERT\n",
      "\n",
      "    with open(ipy_file_path) as fp:\n",
      "        notebook = read(fp, NO_CONVERT)\n",
      "\n",
      "    cells = notebook['cells']\n",
      "    code_cells = [c for c in cells if c['cell_type'] == 'code']\n",
      "    notebook_script = \"\"\n",
      "    for cell in code_cells:\n",
      "        notebook_script += cell.source\n",
      "    print(notebook_script)\n",
      "    with open(target_file_name, \"w\") as f_obj:\n",
      "        f_obj.write(notebook_script)\n",
      "new\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb80e1-ce5b-4384-864b-ec32b7a8847e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a7f94-80cd-4092-aebf-b5799c190488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e553a9-df72-46ac-bae8-713c0ae90fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b4fb8-998a-4b18-ac79-4c8164a7db6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12031f-7cb2-4bc4-9fe5-bfd920a20fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05055078-721b-4119-8c8f-4d83b317f184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf161c7d-d0d4-4b1f-ab35-84b5646ed235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
